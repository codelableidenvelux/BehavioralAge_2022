{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import tie.dbutils as db\n",
    "import pandas as pd\n",
    "from scipy.io import savemat, loadmat\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "import itertools\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "np.random.seed(42)\n",
    "import shap\n",
    "\n",
    "from xgboost import cv\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.colors as colors\n",
    "import copy\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('font', **{'family':'sans-serif',\n",
    "              'sans-serif':['Helvetica']})\n",
    "FONT_SIZE = 25\n",
    "params = {'axes.labelsize': FONT_SIZE,\n",
    "          'axes.titlesize': FONT_SIZE, \n",
    "          'legend.fontsize': FONT_SIZE, \n",
    "          'xtick.labelsize': FONT_SIZE, \n",
    "          'ytick.labelsize': FONT_SIZE}\n",
    "matplotlib.rcParams.update(params)\n",
    "# sns.set_theme(style=\"ticks\", palette='twilight_shifted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = loadmat('info_age_length_age_ml_v15.mat')\n",
    "info.keys()\n",
    "ages = info['ages']\n",
    "genders = info['genders']\n",
    "n_days = info['n_days']\n",
    "\n",
    "ages = ages[n_days >= 7]\n",
    "genders = genders[n_days >= 7]\n",
    "n_days = n_days[n_days >= 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "## AGE\n",
    "ax[0].hist(np.squeeze(ages), bins=20, color='grey')\n",
    "\n",
    "ax[0].set_xlabel(\"Age [years]\")\n",
    "ax[0].set_ylabel(\"No. of subjects [count]\")\n",
    "ax[0].grid(False)\n",
    "\n",
    "## DAYS\n",
    "n, bins, _ = ax[1].hist(np.squeeze(n_days), 100, density=True, histtype='step',\n",
    "                           cumulative=True, color='grey', alpha=1.0, linewidth=2)\n",
    "# ax[1].step(np.cumsum(sorted(full_info[\"days\"])[::-1]), np.cumsum(sorted(full_info[\"days\"])[::-1]) / full_info[\"days\"].sum(), color='grey')\n",
    "# full_info[\"days\"].hist(bins=20, ax=ax[1], color='grey')\n",
    "\n",
    "ax[1].set_xlabel(\"Duration of smartphone recordings [days]\")\n",
    "ax[1].set_ylabel(\"Cumulative density function\")\n",
    "ax[1].grid(False)\n",
    "\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/xgboost/figure_1_panel_b.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fig1panb = pd.DataFrame(columns={'type', 'N', 'min', 'max', '25th', '50th', '75th'})\n",
    "df_fig1panb['type'] = ['female', 'age', 'days']\n",
    "df_fig1panb['N'] = [np.sum(genders == 2), len(ages), len(n_days)]\n",
    "df_fig1panb['min'] = [np.nan, min(ages), min(n_days)]\n",
    "df_fig1panb['max'] = [np.nan, max(ages), max(n_days)]\n",
    "df_fig1panb['25th'] = [np.nan, np.percentile(ages, 25), np.percentile(n_days, 25)]\n",
    "df_fig1panb['50th'] = [np.nan, np.percentile(ages, 50), np.percentile(n_days, 50)]\n",
    "df_fig1panb['75th'] = [np.nan, np.percentile(ages, 75), np.percentile(n_days, 75)]\n",
    "df_fig1panb.to_csv('./figures/xgboost/figure_1_panel_b.csv', index=False)\n",
    "df_fig1panb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_dict = {'180': 0, '90': 1, '60': 2, '30': 3, '10': 4, '5': 5}\n",
    "new_names = {i:f\"{i // 50}-{i % 50}\" for i in range(2500)}\n",
    "new_names[2500] = \"gender\"\n",
    "new_names[2501] = \"log10(daily count)\"\n",
    "new_names[2502] = \"entropy\"\n",
    "new_names[2503] = \"screen-size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_sp = loadmat('ml_age_data_special_full_v16')\n",
    "X_sp = np.squeeze(Xy_sp['X_all'])\n",
    "y_sp = np.squeeze(Xy_sp['y_all'])\n",
    "g_sp = np.squeeze(Xy_sp['g_all'])\n",
    "u_sp = np.squeeze(Xy_sp['u_all'])\n",
    "e_sp = np.squeeze(Xy_sp['e_all'])\n",
    "d_sp = np.squeeze(Xy_sp['d_all'])\n",
    "n_sp = np.squeeze(Xy_sp['n_all'])\n",
    "s_sp = np.squeeze(Xy_sp['s_all'])\n",
    "print((X_sp.shape, y_sp.shape, g_sp.shape, u_sp.shape, e_sp.shape, d_sp.shape, n_sp.shape, s_sp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = days_dict['180']\n",
    "X_180 = np.squeeze(np.array([a[D][0] for a in X_sp if a[D][0].shape[0] > 0]))\n",
    "y_180 = np.squeeze(np.array([a[D][0][0] for a in y_sp if len(a[D][0][0]) > 0]))\n",
    "g_180 = np.array([a[D][0][0] for a in g_sp if len(a[D][0][0]) > 0])\n",
    "u_180 = np.log10(np.array([a[D][0][0] for a in u_sp if len(a[D][0][0]) > 0]) + 1e-15)\n",
    "e_180 = np.array([a[D][0][0] for a in e_sp if len(a[D][0][0]) > 0])\n",
    "d_180 = np.array([a[D][0][0] for a in d_sp if len(a[D][0][0]) > 0])\n",
    "s_180 = np.array([a[D][0][0] for a in s_sp if len(a[D][0][0]) > 0])\n",
    "X_180.shape, y_180.shape, g_180.shape, s_180.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_180 = np.concatenate([X_180, g_180, u_180, e_180, s_180], axis=1)\n",
    "X_180.shape, y_180.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_180 = pd.DataFrame(X_180)\n",
    "X_df_180 = X_df_180.rename(columns=new_names)\n",
    "X_df_180.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = days_dict['90']\n",
    "X_90 = np.squeeze(np.array([a[D][0] for a in X_sp if a[D][0].shape[0] > 0]))\n",
    "y_90 = np.squeeze(np.array([a[D][0][0] for a in y_sp if len(a[D][0][0]) > 0]))\n",
    "g_90 = np.array([a[D][0][0] for a in g_sp if len(a[D][0][0]) > 0])\n",
    "u_90 = np.log10(np.array([a[D][0][0] for a in u_sp if len(a[D][0][0]) > 0]) + 1e-15)\n",
    "e_90 = np.array([a[D][0][0] for a in e_sp if len(a[D][0][0]) > 0])\n",
    "d_90 = np.array([a[D][0][0] for a in d_sp if len(a[D][0][0]) > 0])\n",
    "s_90 = np.array([a[D][0][0] for a in s_sp if len(a[D][0][0]) > 0])\n",
    "X_90.shape, y_90.shape, g_90.shape, s_90.shape\n",
    "\n",
    "X_90 = np.concatenate([X_90, g_90, u_90, e_90, s_90], axis=1)\n",
    "X_90.shape, y_180.shape\n",
    "\n",
    "X_df_90 = pd.DataFrame(X_90)\n",
    "X_df_90 = X_df_90.rename(columns=new_names)\n",
    "X_df_90.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X_df_180,label=y_180)\n",
    "\n",
    "params = {'objective':'reg:squarederror',  'colsample_bytree': 0.6,'learning_rate': 0.01, \n",
    "          'subsample':0.7, 'max_depth': 5, 'reg_alpha': 0.001, 'reg_lambda': 0, 'min_child_weight': 8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "TH = 7\n",
    "all_train_pred = []\n",
    "all_train_true = []\n",
    "all_test_pred = []\n",
    "all_test_true = []\n",
    "all_models = []\n",
    "train_used = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X_df_180):\n",
    "#     print(\"TRAIN:\", train_index[:3], \"TEST:\", test_index[:3])\n",
    "    X_train, X_test = X_df_180.iloc[train_index], X_df_180.iloc[test_index]\n",
    "    y_train, y_test = y_180[train_index], y_180[test_index]\n",
    "#     print(X_train.shape, X_test.shape)\n",
    "    d_train, d_test = np.squeeze(d_180[train_index]), np.squeeze(d_180[test_index])\n",
    "    \n",
    "    X_train = X_train[d_train >= TH]\n",
    "    y_train = y_train[d_train >= TH]\n",
    "    train_used += np.sum(d_train >= TH)\n",
    "    print(f\"TR {np.sum(d_train >= TH) / len(d_train) * 100:.2f}%\")\n",
    "    \n",
    "    model = xgb.XGBRegressor(n_estimators=560, **params).fit(X_train, y_train)\n",
    "    all_models.append(model)\n",
    "    pred_vals_train = model.predict(X_train)\n",
    "    pred_vals_test = model.predict(X_test)\n",
    "    \n",
    "    all_train_pred.extend(pred_vals_train)\n",
    "    all_test_pred.extend(pred_vals_test)\n",
    "    all_train_true.extend(y_train)\n",
    "    all_test_true.extend(y_test)\n",
    "    print(f\"TR : {np.mean(np.abs(np.array(all_train_pred) - np.array(all_train_true))):.2f} - TE : {np.mean(np.abs(np.array(all_test_pred) - np.array(all_test_true))):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "TH = 7\n",
    "all_train_pred_90 = []\n",
    "all_train_true_90 = []\n",
    "all_test_pred_90 = []\n",
    "all_test_true_90 = []\n",
    "all_models_90 = []\n",
    "train_used = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X_df_90):\n",
    "#     print(\"TRAIN:\", train_index[:3], \"TEST:\", test_index[:3])\n",
    "    X_train, X_test = X_df_90.iloc[train_index], X_df_90.iloc[test_index]\n",
    "    y_train, y_test = y_90[train_index], y_90[test_index]\n",
    "#     print(X_train.shape, X_test.shape)\n",
    "    d_train, d_test = np.squeeze(d_90[train_index]), np.squeeze(d_90[test_index])\n",
    "    \n",
    "    X_train = X_train[d_train >= TH]\n",
    "    y_train = y_train[d_train >= TH]\n",
    "    train_used += np.sum(d_train >= TH)\n",
    "    print(f\"TR {np.sum(d_train >= TH) / len(d_train) * 100:.2f}%\")\n",
    "    \n",
    "    model = xgb.XGBRegressor(n_estimators=560, **params).fit(X_train, y_train)\n",
    "    all_models_90.append(model)\n",
    "    pred_vals_train = model.predict(X_train)\n",
    "    pred_vals_test = model.predict(X_test)\n",
    "    \n",
    "    all_train_pred_90.extend(pred_vals_train)\n",
    "    all_test_pred_90.extend(pred_vals_test)\n",
    "    all_train_true_90.extend(y_train)\n",
    "    all_test_true_90.extend(y_test)\n",
    "    print(f\"TR : {np.mean(np.abs(np.array(all_train_pred_90) - np.array(all_train_true_90))):.2f} - TE : {np.mean(np.abs(np.array(all_test_pred_90) - np.array(all_test_true_90))):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4.6))\n",
    "\n",
    "pred_vals = np.array(all_test_pred)\n",
    "real_vals = np.array(all_test_true)\n",
    "\n",
    "s_idx = np.argsort(real_vals)\n",
    "ax.scatter(np.arange(len(s_idx)),real_vals[s_idx], marker='.', c='b', label='Chronological age')  \n",
    "ax.scatter(np.arange(len(s_idx)), pred_vals[s_idx], marker='.', s=100, c='orange', label='Predicted age')  \n",
    "ax.grid(False)\n",
    "ax.legend(loc='upper center',  ncol=1, bbox_to_anchor=[.5, 1.3])\n",
    "\n",
    "ax.set_ylabel('Age [years]')\n",
    "ax.set_xlabel('Subject No. (Sorted by age)');\n",
    "ax.set_ylim([0, 100])\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.tight_layout();\n",
    "plt.savefig('figures/xgboost/figure_1_panel_c.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shap = []\n",
    "all_test = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_df_180)):\n",
    "    _, X_test = X_df_180.iloc[train_index], X_df_180.iloc[test_index]\n",
    "    _, y_test = y_180[train_index], y_180[test_index]\n",
    "    explainer = shap.Explainer(all_models[i])\n",
    "    shap_values = explainer(X_test)\n",
    "    all_shap.extend(shap_values)\n",
    "    all_test.extend(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 8))\n",
    "gs0 = gridspec.GridSpec(1, 4, figure=fig, width_ratios=[1, 0.05, 1, 0.05])\n",
    "\n",
    "labels = ['0.03', '0.1', '1', '4', '20']\n",
    "ticks = np.arange(50)[::10]\n",
    "\n",
    "shap_values = all_shap\n",
    "pos_val = np.zeros((len(shap_values), 50, 50)) * np.nan\n",
    "neg_val = np.zeros((len(shap_values), 50, 50)) * np.nan\n",
    "pos_extra = np.zeros((len(shap_values), 4)) * np.nan\n",
    "neg_extra = np.zeros((len(shap_values), 4)) * np.nan\n",
    "for IDX in range(len(shap_values)):\n",
    "    _pos = copy.deepcopy(np.reshape(shap_values[IDX].values[:2500], (50, 50)))\n",
    "    _neg = copy.deepcopy(np.reshape(shap_values[IDX].values[:2500], (50, 50)))\n",
    "    _pos_e = copy.deepcopy(shap_values[IDX].values[2500:])\n",
    "    _neg_e = copy.deepcopy(shap_values[IDX].values[2500:])\n",
    "    \n",
    "    _pos[_pos < 0] = 0\n",
    "    pos_val[IDX] = _pos\n",
    "    _pos_e[_pos_e < 0] = 0\n",
    "    pos_extra[IDX] = _pos_e\n",
    "    \n",
    "    _neg[_neg > 0] = 0\n",
    "    neg_val[IDX] = _neg\n",
    "    _neg_e[_neg_e > 0] = 0\n",
    "    neg_extra[IDX] = _neg_e\n",
    "\n",
    "    \n",
    "m_pos = np.nanmean(pos_val, 0)\n",
    "mask = np.ones_like(m_pos)\n",
    "mask[m_pos < 0.01] = np.nan\n",
    "ax0 = fig.add_subplot(gs0[0, 0])\n",
    "im = ax0.imshow(m_pos * mask, cmap='Reds', vmax=1.2, vmin=0, aspect='auto')\n",
    "ax0.invert_yaxis()\n",
    "divider = make_axes_locatable(ax0)\n",
    "cax = divider.new_vertical(size=\"5%\", pad=.1, pack_start=False)\n",
    "fig.add_axes(cax)\n",
    "cb = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "cb.ax.xaxis.set_ticks_position('top')\n",
    "ax0.set_xticks(ticks)\n",
    "ax0.set_xticklabels(labels)\n",
    "ax0.xaxis.set_tick_params(rotation=45)\n",
    "ax0.set_yticks(ticks)\n",
    "ax0.set_yticklabels(labels)\n",
    "ax0.set_ylabel(r'$ITI(k + 1)$ [s]')\n",
    "ax0.set_xlabel(r'$ITI(k)$ [s]')\n",
    "ax0.text(-11, 50.1, 'Mean\\nShapley\\nvalue', size=25)\n",
    "    \n",
    "    \n",
    "ax01 = fig.add_subplot(gs0[0, 1])\n",
    "ax01.imshow(np.nanmean(pos_extra, 0)[:, None], vmax=1.2, vmin=0, cmap='Reds', aspect='auto')\n",
    "ax01.yaxis.tick_right()\n",
    "ax01.set_xticks([])\n",
    "ax01.set_yticks([0, 1, 2, 3])\n",
    "ax01.set_yticklabels([new_names[2500], new_names[2501], new_names[2502], new_names[2503]], rotation=90, size=15, verticalalignment='center')\n",
    "\n",
    "# ax99 = fig.add_subplot(gs0[0, 2])\n",
    "# ax99.set_xticks([])\n",
    "# ax99.set_yticks([])\n",
    "# ax99.spines['right'].set_visible(False)\n",
    "# ax99.spines['top'].set_visible(False)\n",
    "# ax99.spines['left'].set_visible(False)\n",
    "# ax99.spines['bottom'].set_visible(False)\n",
    "\n",
    "m_neg = np.nanmean(neg_val, 0)\n",
    "mask = np.ones_like(m_neg)\n",
    "mask[m_neg > -0.01] = np.nan\n",
    "ax1 = fig.add_subplot(gs0[0, 2])\n",
    "im = ax1.imshow(m_neg * mask, cmap=\"Blues_r\", vmin=-0.8, vmax=0, aspect='auto')\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.new_vertical(size=\"5%\", pad=.1, pack_start=False)\n",
    "fig.add_axes(cax)\n",
    "cb = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "cb.ax.xaxis.set_ticks_position('top')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xticks(ticks)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.xaxis.set_tick_params(rotation=45)\n",
    "ax1.set_yticks(ticks)\n",
    "ax1.set_yticklabels(labels)\n",
    "ax1.set_ylabel(r'$ITI(k + 1)$ [s]')\n",
    "ax1.set_xlabel(r'$ITI(k)$ [s]')\n",
    "ax1.text(-11, 50.1, 'Mean\\nShapley\\nvalue', size=25)\n",
    "\n",
    "ax11 = fig.add_subplot(gs0[0, 3])\n",
    "ax11.imshow(np.nanmean(neg_extra, 0)[:, None], vmin=-0.8, vmax=0, cmap='Blues_r', aspect='auto')\n",
    "ax11.yaxis.tick_right()\n",
    "ax11.set_xticks([])\n",
    "ax11.set_yticks([0, 1, 2, 3])\n",
    "ax11.set_yticklabels([new_names[2500], new_names[2501], new_names[2502], new_names[2503]], rotation=90, size=15, verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/xgboost/figure_1_panel_e.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "all_test_pred = []\n",
    "all_test_true = []\n",
    "all_regr_sp = []\n",
    "all_train_pred = []\n",
    "all_train_true = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_sp):\n",
    "    X_train = X_sp[train_index]\n",
    "    y_train = y_sp[train_index]\n",
    "    X_test = X_sp[test_index]\n",
    "    y_test = y_sp[test_index]\n",
    "    g_train = g_sp[train_index]\n",
    "    g_test = g_sp[test_index]\n",
    "    u_train = u_sp[train_index]\n",
    "    u_test = u_sp[test_index]\n",
    "    e_train = e_sp[train_index]\n",
    "    e_test = e_sp[test_index]\n",
    "    d_train = d_sp[train_index]\n",
    "    d_test = d_sp[test_index]\n",
    "    s_train = s_sp[train_index]\n",
    "    s_test = s_sp[test_index]\n",
    "    \n",
    "    D = days_dict['180']\n",
    "    X_d = np.squeeze(np.array([a[D][0] for a in X_train if a[D][0].shape[0] > 0]))\n",
    "    y_tr = np.squeeze(np.array([a[D][0][0] for a in y_train if len(a[D][0][0]) > 0]))\n",
    "    g_d = np.array([a[D][0][0] for a in g_train if len(a[D][0][0]) > 0])\n",
    "    u_d = np.log10(np.array([a[D][0][0] for a in u_train if len(a[D][0][0]) > 0]) + 1e-15)\n",
    "    e_d = np.array([a[D][0][0] for a in e_train if len(a[D][0][0]) > 0])\n",
    "    d_d = np.squeeze(np.array([a[D][0][0] for a in d_train if len(a[D][0][0]) > 0]))\n",
    "    s_d = np.array([a[D][0][0] for a in s_train if len(a[D][0][0]) > 0])\n",
    "    X_d = np.concatenate([X_d, g_d, u_d, e_d, s_d], axis=1)\n",
    "    \n",
    "    X_d = X_d[d_d >= TH]\n",
    "    y_tr = y_tr[d_d >= TH]\n",
    "    train_used += np.sum(d_d >= TH)\n",
    "    print(f\"TR {np.sum(d_d >= TH) / len(d_d) * 100:.2f}%\")\n",
    "    \n",
    "    X_df_train = pd.DataFrame(X_d)\n",
    "    X_df_train = X_df_train.rename(columns=new_names)\n",
    "    \n",
    "    X_d = np.squeeze(np.array([a[D][0] for a in X_test if a[D][0].shape[0] > 0]))\n",
    "    y_te = np.squeeze(np.array([a[D][0][0] for a in y_test if len(a[D][0][0]) > 0]))\n",
    "    g_d = np.array([a[D][0][0] for a in g_test if len(a[D][0][0]) > 0])\n",
    "    u_d = np.log10(np.array([a[D][0][0] for a in u_test if len(a[D][0][0]) > 0]) + 1e-15)\n",
    "    e_d = np.array([a[D][0][0] for a in e_test if len(a[D][0][0]) > 0])\n",
    "    d_d = np.array([a[D][0][0] for a in d_test if len(a[D][0][0]) > 0])\n",
    "    s_d = np.array([a[D][0][0] for a in s_test if len(a[D][0][0]) > 0])\n",
    "    X_d = np.concatenate([X_d, g_d, u_d, e_d, s_d], axis=1)\n",
    "    X_df_test = pd.DataFrame(X_d)\n",
    "    X_df_test = X_df_test.rename(columns=new_names)\n",
    "\n",
    "    model = xgb.XGBRegressor(n_estimators=559, tree_method='gpu_hist', **params).fit(X_df_train, y_tr)\n",
    "    all_regr_sp.append(model)\n",
    "    pred_vals_train = model.predict(X_df_train)\n",
    "    pred_vals_test = model.predict(X_df_test)\n",
    "    \n",
    "    all_train_pred.extend(pred_vals_train)\n",
    "    all_train_true.extend(y_tr)\n",
    "    \n",
    "    to_append_pred_test = [pred_vals_test]\n",
    "    to_append_true_test = [y_te]\n",
    "    \n",
    "    for _days in ['90', '60', '30', '10', '5']:\n",
    "        D = days_dict[_days]\n",
    "        X_d = np.squeeze(np.array([a[D][0] for a in X_test if a[D][0].shape[0] > 0]))\n",
    "        y_d = np.squeeze(np.array([a[D][0][0] for a in y_test if len(a[D][0][0]) > 0]))\n",
    "        g_d = np.array([a[D][0][0] for a in g_test if len(a[D][0][0]) > 0])\n",
    "        u_d = np.log10(np.array([a[D][0][0] for a in u_test if len(a[D][0][0]) > 0]) + 1e-15)\n",
    "        e_d = np.array([a[D][0][0] for a in e_test if len(a[D][0][0]) > 0])\n",
    "        d_d = np.array([a[D][0][0] for a in d_test if len(a[D][0][0]) > 0])\n",
    "        s_d = np.array([a[D][0][0] for a in s_test if len(a[D][0][0]) > 0])\n",
    "        X_d = np.concatenate([X_d, g_d, u_d, e_d, s_d], axis=1)\n",
    "        X_df_d = pd.DataFrame(X_d)\n",
    "        X_df_d = X_df_d.rename(columns=new_names)\n",
    "        pred_vals_d = model.predict(X_df_d)\n",
    "        \n",
    "        to_append_pred_test.append(pred_vals_d)\n",
    "        to_append_true_test.append(y_d)\n",
    "        \n",
    "    all_test_pred.append(to_append_pred_test)\n",
    "    all_test_true.append(to_append_true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_mae = [[] for _ in range(6)]\n",
    "errors = [[] for _ in range(6)]\n",
    "all_r2_pred = [[] for _ in range(6)]\n",
    "all_r2_true = [[] for _ in range(6)]\n",
    "\n",
    "for days in range(6):\n",
    "    for fold in range(10):\n",
    "        errors_mae[days].extend(np.abs(all_test_pred[fold][days] - all_test_true[fold][days]))\n",
    "        errors[days].extend(all_test_pred[fold][days] - all_test_true[fold][days])\n",
    "        all_r2_pred[days].extend(all_test_pred[fold][days])\n",
    "        all_r2_true[days].extend(all_test_true[fold][days])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.concat([pd.DataFrame({\"error\": errors[i], \"error_mae\": errors_mae[i], \"days\": np.ones(len(errors[i])) * d}) for i, d in enumerate([180, 90, 60, 30, 10, 5])], 0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "sns.lineplot(data=a.reset_index(drop=True), x='days', y='error_mae', ax=ax, marker='p', markersize=10)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel(\"Duration of recording\\nconsidered [Max. days]\")\n",
    "ax.set_ylabel(\"MAE [years]\")\n",
    "ax.set(xscale=\"log\")\n",
    "ax.set_xticks([5, 10, 30, 60, 90, 180]);\n",
    "ax.get_xaxis().get_major_formatter().labelOnlyBase = False\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/xgboost/figure_1_panel_d.pdf')\n",
    "\n",
    "df_fig1pand = pd.DataFrame(columns={'N', '25th', '50th', '75th', 'mean', 'MAE', 'R2', 'days'})\n",
    "df_fig1pand['days'] = ['5', '10', '30', '60', '90', '180']\n",
    "df_fig1pand['N'] = [len(a[a['days'] == 5]['error']), \n",
    "                    len(a[a['days'] == 10]['error']), \n",
    "                    len(a[a['days'] == 30]['error']),\n",
    "                    len(a[a['days'] == 60]['error']), \n",
    "                    len(a[a['days'] == 90]['error']), \n",
    "                    len(a[a['days'] == 180]['error'])]\n",
    "\n",
    "df_fig1pand['25th'] = [np.percentile(a[a['days'] == 5]['error'], 25), \n",
    "                       np.percentile(a[a['days'] == 10]['error'], 25), \n",
    "                       np.percentile(a[a['days'] == 30]['error'], 25), \n",
    "                       np.percentile(a[a['days'] == 60]['error'], 25), \n",
    "                       np.percentile(a[a['days'] == 90]['error'], 25), \n",
    "                       np.percentile(a[a['days'] == 180]['error'], 25)]\n",
    "\n",
    "df_fig1pand['50th'] = [np.percentile(a[a['days'] == 5]['error'], 50), \n",
    "                       np.percentile(a[a['days'] == 10]['error'], 50), \n",
    "                       np.percentile(a[a['days'] == 30]['error'], 50), \n",
    "                       np.percentile(a[a['days'] == 60]['error'], 50), \n",
    "                       np.percentile(a[a['days'] == 90]['error'], 50), \n",
    "                       np.percentile(a[a['days'] == 180]['error'], 50)]\n",
    "\n",
    "df_fig1pand['75th'] = [np.percentile(a[a['days'] == 5]['error'], 75), \n",
    "                       np.percentile(a[a['days'] == 10]['error'], 75), \n",
    "                       np.percentile(a[a['days'] == 30]['error'], 75), \n",
    "                       np.percentile(a[a['days'] == 60]['error'], 75), \n",
    "                       np.percentile(a[a['days'] == 90]['error'], 75), \n",
    "                       np.percentile(a[a['days'] == 180]['error'], 75)]\n",
    "\n",
    "df_fig1pand['mean'] = [np.mean(a[a['days'] == 5]['error']), \n",
    "                       np.mean(a[a['days'] == 10]['error']), \n",
    "                       np.mean(a[a['days'] == 30]['error']), \n",
    "                       np.mean(a[a['days'] == 60]['error']), \n",
    "                       np.mean(a[a['days'] == 90]['error']), \n",
    "                       np.mean(a[a['days'] == 180]['error'])]\n",
    "\n",
    "df_fig1pand['MAE'] = [np.mean(a[a['days'] == 5]['error'].abs()), \n",
    "                      np.mean(a[a['days'] == 10]['error'].abs()), \n",
    "                      np.mean(a[a['days'] == 30]['error'].abs()), \n",
    "                      np.mean(a[a['days'] == 60]['error'].abs()), \n",
    "                      np.mean(a[a['days'] == 90]['error'].abs()), \n",
    "                      np.mean(a[a['days'] == 180]['error'].abs())]\n",
    "\n",
    "df_fig1pand['R2'] = [r2_score(all_r2_true[5], all_r2_pred[5]), \n",
    "                      r2_score(all_r2_true[4], all_r2_pred[4]),\n",
    "                      r2_score(all_r2_true[3], all_r2_pred[3]),\n",
    "                      r2_score(all_r2_true[2], all_r2_pred[2]),\n",
    "                      r2_score(all_r2_true[1], all_r2_pred[1]),\n",
    "                      r2_score(all_r2_true[0], all_r2_pred[0]),\n",
    "                     ]\n",
    "\n",
    "df_fig1pand.to_csv('figures/xgboost/figure_1_panel_d.csv', index=False)\n",
    "df_fig1pand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_stroke_all = loadmat('ml_age_STROKE_data_v14.mat')\n",
    "X_stroke_all = np.squeeze(Xy_stroke_all['X_all'])\n",
    "y_stroke_all = np.squeeze(Xy_stroke_all['y_all'])\n",
    "g_stroke_all = np.squeeze(Xy_stroke_all['g_all'])\n",
    "u_stroke_all = np.squeeze(Xy_stroke_all['u_all'])\n",
    "e_stroke_all = np.squeeze(Xy_stroke_all['e_all'])\n",
    "s_stroke_all = np.squeeze(Xy_stroke_all['s_all'])\n",
    "print((X_stroke_all.shape, y_stroke_all.shape, g_stroke_all.shape, u_stroke_all.shape, e_stroke_all.shape, s_stroke_all.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stroke_test = X_stroke_all[:]\n",
    "y_stroke_test = y_stroke_all[:]\n",
    "g_stroke_test = g_stroke_all[:]\n",
    "u_stroke_test = u_stroke_all[:]\n",
    "e_stroke_test = e_stroke_all[:]\n",
    "s_stroke_test = s_stroke_all[:]\n",
    "\n",
    "# only first\n",
    "X_stroke_sub_test = np.array([a[:, 0] for a in X_stroke_test])\n",
    "y_stroke_sub_test = np.squeeze(np.array([a[0] for a in y_stroke_test]))\n",
    "g_stroke_sub_test = np.array([a[0] for a in g_stroke_test]) * 1\n",
    "u_stroke_sub_test = np.log10(np.array([a[0] for a in u_stroke_test]) + 1e-15) * 1\n",
    "e_stroke_sub_test = np.array([a[0] for a in e_stroke_test]) * 1\n",
    "s_stroke_sub_test = np.array([a[0] for a in s_stroke_test])\n",
    "\n",
    "\n",
    "# put tog.\n",
    "X_stroke_test = np.concatenate([X_stroke_sub_test[:, :], g_stroke_sub_test, u_stroke_sub_test, e_stroke_sub_test, s_stroke_sub_test], -1)\n",
    "print(X_stroke_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s_df = pd.DataFrame(X_stroke_test)\n",
    "X_s_df = X_s_df.rename(columns=new_names)\n",
    "X_s_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_stroke_ages = []\n",
    "\n",
    "for _model in all_models_90:\n",
    "    pred_vals_test_s = _model.predict(X_s_df)\n",
    "    all_pred_stroke_ages.append(pred_vals_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_zeros = [np.int32(a.predict(X_s_df * 0)[0]) for a in all_models_90]\n",
    "print(all_pred_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_stroke = np.vstack(all_pred_stroke_ages)\n",
    "min_s_stroke = np.percentile(stacked_stroke, 2.5, 0)\n",
    "max_s_stroke = np.percentile(stacked_stroke, 97.5, 0)\n",
    "med_s_stroke = np.percentile(stacked_stroke, 50, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_90 = np.array(all_test_true_90) - np.array(all_test_pred_90)\n",
    "chained_real = np.array(all_test_true_90)\n",
    "chained_90 = np.array(all_test_pred_90)\n",
    "all_real_90 = np.array(all_test_true_90)\n",
    "all_pred_90 = np.array(all_test_pred_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample based on stroke distribution\n",
    "nboot = 10000\n",
    "subsets_true = []\n",
    "subsets_pred = []\n",
    "for _ in range(nboot):\n",
    "    to_add_true = []\n",
    "    to_add_pred = []\n",
    "    for x in y_stroke_sub_test:\n",
    "        _true_matched = chained_real[chained_real == x]\n",
    "        _pred_matched = chained_90[chained_real == x]\n",
    "        if len(_true_matched) == 0:  # if I don't have 83 I try with 84 anyway is close enough to match the distro\n",
    "            _true_matched = chained_real[chained_real == x + 1]\n",
    "            _pred_matched = error_90[chained_real == x + 1]\n",
    "        _idx = np.random.choice(len(_true_matched))\n",
    "        to_add_true.append(_true_matched[_idx])\n",
    "        to_add_pred.append(_pred_matched[_idx])\n",
    "    subsets_pred.append(np.array(to_add_pred))\n",
    "    subsets_true.append(np.array(to_add_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(22, 10))\n",
    "\n",
    "idx = np.argsort(y_stroke_sub_test)\n",
    "\n",
    "ss = np.linspace(-0.0, 40, 41)\n",
    "\n",
    "ax[1].fill_between(ss, min_s_stroke[idx], max_s_stroke[idx], color='k', alpha=0.1, zorder=3)\n",
    "ax[1].scatter(np.arange(len(idx)), y_stroke_sub_test[idx], marker='o', color='blue', label='Chronological age')\n",
    "ax[1].scatter(np.arange(len(idx)), med_s_stroke[idx], marker='o', c='orange', label='Predicted age')\n",
    "ax[1].set_xlabel('Subject No. (Sorted by age)')\n",
    "ax[1].set_ylabel('Age [years]')\n",
    "# ax[1].plot([0, 40], [np.mean(ages), np.mean(ages)], 'k--', alpha=1.0, label='Mean age (healthy training set)')\n",
    "ax[1].plot([0, 40], [np.mean(all_pred_zeros), np.mean(all_pred_zeros)], 'r--', alpha=1.0, label='Default output')\n",
    "ax[1].fill_between(ss, np.percentile(all_pred_zeros, 2.5), np.percentile(all_pred_zeros, 97.5), color='r', alpha=0.1, zorder=3)\n",
    "\n",
    "handles, labels = ax[1].get_legend_handles_labels()\n",
    "order = [1, 2, 0]\n",
    "ax[1].legend([handles[idx] for idx in order],[labels[idx] for idx in order], loc='upper left', shadow=False, fancybox=False, ncol=1, bbox_to_anchor=[0.0, 1.6])\n",
    "\n",
    "ax[1].grid(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].set_ylim([18, 85])\n",
    "X = np.array([np.median(a - y_stroke_sub_test) for a in all_pred_stroke_ages])\n",
    "# X = list(itertools.chain.from_iterable([a - y_stroke_sub_test for a in all_pred_stroke_ages]))\n",
    "# ax[0].hist(X)\n",
    "sns.kdeplot(X, ax=ax[0], bw_method=.6, linewidth=3, label='Stroke survivors', color='blue')\n",
    "Y = [np.median(a - b) for a, b in zip(subsets_true, subsets_pred)]\n",
    "# Y = list(itertools.chain.from_iterable([a - b for a, b in zip(subsets_true, subsets_pred)]))\n",
    "sns.kdeplot(Y, ax=ax[0], bw_method=.3, linewidth=3, label='Healthy population (age matched)', color='g')\n",
    "# ax[0].hist(Y, color='g')\n",
    "\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].legend(shadow=False, fancybox=False, ncol=1, bbox_to_anchor=[.7, 1.6])\n",
    "ax[0].set_xlabel(\"Error [years]\")\n",
    "ax[0].set_ylabel(\"Probability density\")\n",
    "ax[0].grid(False)\n",
    "ax[0].set_xlim([-10, 13])\n",
    "ax[0].set_ylim([0, 0.6])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/xgboost/figure_2_panel_d_stroke.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tval, pval = ttest_ind(X, Y)\n",
    "\n",
    "df_fig2_stroke = pd.DataFrame({'type': ['stroke distro', 'healthy distro', 't-test'], \n",
    "                        'p-val': [np.nan, np.nan, pval],\n",
    "                        't-val': [np.nan, np.nan, tval], \n",
    "                        '25th': [np.percentile(X, 25),np.percentile(Y, 25), np.nan],\n",
    "                        '50th': [np.percentile(X, 50),np.percentile(Y, 50), np.nan],\n",
    "                        '75th': [np.percentile(X, 75),np.percentile(Y, 75), np.nan],\n",
    "                        'mean': [np.mean(X),np.mean(Y), np.nan],\n",
    "                        'MAE': [np.mean(np.abs(y_stroke_sub_test - med_s_stroke)),np.nan, np.nan]\n",
    "                           })\n",
    "df_fig2_stroke.to_csv('./figures/xgboost/fig2_stroke_stats.csv')\n",
    "df_fig2_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame({'Age': y_stroke_sub_test[idx], 'Pred' : med_s_stroke[idx]})\n",
    "fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
    "sns.regplot(y=\"Pred\", x=\"Age\", data=df_);\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Pred');\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.savefig('./figures/xgboost/figure_2_insert_stroke.pdf')\n",
    "savemat('figure_2_xgboost_insert_stroke.mat', {'real_str': y_stroke_sub_test[idx], 'pred_str': med_s_stroke[idx]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epilepsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_rns_all = loadmat('ml_age_RNS_data_v15.mat')\n",
    "X_rns_all = np.squeeze(Xy_rns_all['X_all'])\n",
    "y_rns_all = np.squeeze(Xy_rns_all['y_all'])\n",
    "g_rns_all = np.squeeze(Xy_rns_all['g_all'])\n",
    "u_rns_all = np.squeeze(Xy_rns_all['u_all'])\n",
    "e_rns_all = np.squeeze(Xy_rns_all['e_all'])\n",
    "s_rns_all = np.squeeze(Xy_rns_all['s_all'])\n",
    "partId_rns_all = np.squeeze(Xy_rns_all['partId_all'])\n",
    "print((X_rns_all.shape, y_rns_all.shape, g_rns_all.shape, u_rns_all.shape, e_rns_all.shape, s_rns_all.shape, partId_rns_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rns_test = X_rns_all[:]\n",
    "y_rns_test = y_rns_all[:]\n",
    "g_rns_test = g_rns_all[:]\n",
    "u_rns_test = u_rns_all[:]\n",
    "e_rns_test = e_rns_all[:]\n",
    "s_rns_test = s_rns_all[:]\n",
    "\n",
    "# only first\n",
    "X_rns_sub_test = np.array([a[:, 0] for a in X_rns_test])\n",
    "y_rns_sub_test = np.squeeze(np.array([a[0] for a in y_rns_test]))\n",
    "g_rns_sub_test = np.array([a[0] for a in g_rns_test]) * 1\n",
    "u_rns_sub_test = np.log10(np.array([a[0] for a in u_rns_test]) + 1e-15) * 1\n",
    "e_rns_sub_test = np.array([a[0] for a in e_rns_test]) * 1\n",
    "s_rns_sub_test = np.array([a[0] for a in s_rns_test]) * 1\n",
    "\n",
    "\n",
    "# put tog.\n",
    "X_rns_test = np.concatenate([X_rns_sub_test[:, :], g_rns_sub_test, u_rns_sub_test, e_rns_sub_test, s_rns_sub_test], -1)\n",
    "print(X_rns_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r_df = pd.DataFrame(X_rns_test)\n",
    "X_r_df = X_r_df.rename(columns=new_names)\n",
    "X_r_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_rns_ages = [a.predict(X_r_df) for a in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_epi_all = loadmat('ml_age_epi_data_v16.mat')\n",
    "X_epi_all = np.squeeze(Xy_epi_all['X_all'])\n",
    "y_epi_all = np.squeeze(Xy_epi_all['y_all'])\n",
    "g_epi_all = np.squeeze(Xy_epi_all['g_all'])\n",
    "u_epi_all = np.squeeze(Xy_epi_all['u_all'])\n",
    "e_epi_all = np.squeeze(Xy_epi_all['e_all'])\n",
    "s_epi_all = np.squeeze(Xy_epi_all['s_all'])\n",
    "partId_epi_all = np.squeeze(Xy_epi_all['partId_all'])\n",
    "print((X_epi_all.shape, y_epi_all.shape, g_epi_all.shape, u_epi_all.shape, e_epi_all.shape, s_epi_all.shape, partId_epi_all.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_epi_test = X_epi_all[:]\n",
    "y_epi_test = y_epi_all[:]\n",
    "g_epi_test = g_epi_all[:]\n",
    "u_epi_test = u_epi_all[:]\n",
    "e_epi_test = e_epi_all[:]\n",
    "s_epi_test = s_epi_all[:]\n",
    "\n",
    "# only first\n",
    "X_epi_sub_test = np.array([a[:, 0] for a in X_epi_test])\n",
    "y_epi_sub_test = np.squeeze(np.array([a[0] for a in y_epi_test]))\n",
    "g_epi_sub_test = np.array([a[0] for a in g_epi_test]) * 1\n",
    "u_epi_sub_test = np.log10(np.array([a[0] for a in u_epi_test]) + 1e-15) * 1\n",
    "e_epi_sub_test = np.array([a[0] for a in e_epi_test]) * 1\n",
    "s_epi_sub_test = np.array([a[0] for a in s_epi_test]) * 1\n",
    "\n",
    "\n",
    "# put tog.\n",
    "X_epi_test = np.concatenate([X_epi_sub_test[:, :], g_epi_sub_test, u_epi_sub_test, e_epi_sub_test, s_epi_sub_test], -1)\n",
    "print(X_epi_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_e_df = pd.DataFrame(X_epi_test)\n",
    "X_e_df = X_e_df.rename(columns=new_names)\n",
    "X_e_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_epi_ages = [a.predict(X_e_df) for a in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_rns_ages[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_epilepsy_ages = np.concatenate([all_pred_rns_ages, all_pred_epi_ages], axis=1)\n",
    "all_study_type = np.concatenate([np.ones_like(y_rns_sub_test), 2 * np.ones_like(y_epi_sub_test)])\n",
    "y_epilepsy_sub_test = np.concatenate([y_rns_sub_test, y_epi_sub_test])\n",
    "partId_epilepsy_sub_test = np.concatenate([partId_rns_all, partId_epi_all])\n",
    "all_pred_epilepsy_ages.shape, y_epilepsy_sub_test.shape, partId_epilepsy_sub_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_test_true[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_all = np.array(all_test_true) - np.array(all_test_pred)\n",
    "chained_real_all = np.array(all_test_true)\n",
    "chained_all = np.array(all_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample based on stroke distribution\n",
    "nboot = 10000\n",
    "subsets_true = []\n",
    "subsets_pred = []\n",
    "for _ in range(nboot):\n",
    "    to_add_true = []\n",
    "    to_add_pred = []\n",
    "    for x in y_epilepsy_sub_test:\n",
    "        _true_matched = chained_real_all[chained_real_all == x]\n",
    "        _pred_matched = chained_all[chained_real_all == x]\n",
    "        if len(_true_matched) == 0:  # if I don't have 83 I try with 84 anyway is close enough to match the distro\n",
    "            _true_matched = chained_real_all[chained_real_all == x + 4]\n",
    "            _pred_matched = error_all[chained_real_all == x + 4]\n",
    "        _idx = np.random.choice(len(_true_matched))\n",
    "        to_add_true.append(_true_matched[_idx])\n",
    "        to_add_pred.append(_pred_matched[_idx])\n",
    "    subsets_pred.append(np.array(to_add_pred))\n",
    "    subsets_true.append(np.array(to_add_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_epilepsy = all_pred_epilepsy_ages\n",
    "min_s = np.percentile(stacked_epilepsy, 2.5, 0)\n",
    "max_s = np.percentile(stacked_epilepsy, 97.5, 0)\n",
    "med_s = np.percentile(stacked_epilepsy, 50, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(22, 10))\n",
    "idx = np.argsort(y_epilepsy_sub_test)\n",
    "\n",
    "ss = np.linspace(-0.0, len(idx) - 1, len(idx))\n",
    "\n",
    "ax[1].scatter(np.arange(len(idx))[all_study_type[idx] == 1], y_epilepsy_sub_test[idx][all_study_type[idx] == 1], s=100, marker='o', c='blue', label='Chronological age')\n",
    "ax[1].scatter(np.arange(len(idx))[all_study_type[idx] == 2], y_epilepsy_sub_test[idx][all_study_type[idx] == 2], s=40, marker='o', c='blue')\n",
    "ax[1].fill_between(ss, min_s[idx], max_s[idx], color='k', alpha=0.1, zorder=3)\n",
    "ax[1].scatter(np.arange(len(idx)), med_s[idx], marker='o', c='orange', label='Predicted age')\n",
    "\n",
    "ax[1].set_xlabel('Subject No. (Sorted by age)')\n",
    "ax[1].set_ylabel('Age [years]')\n",
    "# ax[1].plot([0, 40], [np.mean(ages), np.mean(ages)], 'k--', alpha=1.0, label='Mean age (healthy training set)')\n",
    "ax[1].plot([0, len(idx)], [np.mean(all_pred_zeros), np.mean(all_pred_zeros)], 'r--', alpha=1.0, label='Default output')\n",
    "ax[1].fill_between(ss, np.percentile(all_pred_zeros, 2.5), np.percentile(all_pred_zeros, 97.5), color='r', alpha=0.1, zorder=3)\n",
    "\n",
    "handles, labels = ax[1].get_legend_handles_labels()\n",
    "order = [1, 2, 0]\n",
    "ax[1].legend([handles[idx] for idx in order],[labels[idx] for idx in order], loc='upper left', shadow=False, fancybox=False, ncol=1, bbox_to_anchor=[0.0, 1.6])\n",
    "\n",
    "ax[1].grid(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].set_ylim([18, 85])\n",
    "\n",
    "X = np.array([np.median(a - y_epilepsy_sub_test) for a in all_pred_epilepsy_ages])\n",
    "# X = list(itertools.chain.from_iterable([a - y_stroke_sub_test for a in all_pred_stroke_ages]))\n",
    "# ax[0].hist(X)\n",
    "sns.kdeplot(X, ax=ax[0], bw_method=.6, linewidth=3, label='Epilepsy', color='blue')\n",
    "Y = [np.median(a - b) for a, b in zip(subsets_true, subsets_pred)]\n",
    "# Y = list(itertools.chain.from_iterable([a - b for a, b in zip(subsets_true, subsets_pred)]))\n",
    "sns.kdeplot(Y, ax=ax[0], bw_method=.3, linewidth=3, label='Healthy population (age matched)', color='g')\n",
    "# ax[0].hist(Y, color='g')\n",
    "\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].legend(shadow=False, fancybox=False, ncol=1, bbox_to_anchor=[.7, 1.6])\n",
    "ax[0].set_xlabel(\"Error [years]\")\n",
    "ax[0].set_ylabel(\"Probability density\")\n",
    "ax[0].grid(False)\n",
    "ax[0].set_xlim([-10, 13])\n",
    "ax[0].set_ylim([0, 0.7])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/xgboost/figure_2_panel_d_epilepsy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tval, pval = ttest_ind(X, Y)\n",
    "\n",
    "df_fig2_epi = pd.DataFrame({'type': ['epi distro', 'healthy distro', 't-test'], \n",
    "                        'p-val': [np.nan, np.nan, pval],\n",
    "                        't-val': [np.nan, np.nan, tval], \n",
    "                        '25th': [np.percentile(X, 25),np.percentile(Y, 25), np.nan],\n",
    "                        '50th': [np.percentile(X, 50),np.percentile(Y, 50), np.nan],\n",
    "                        '75th': [np.percentile(X, 75),np.percentile(Y, 75), np.nan],\n",
    "                         'mean': [np.mean(X),np.mean(Y), np.nan],\n",
    "                            'MAE': [np.mean(np.abs(y_epilepsy_sub_test - med_s)),np.nan, np.nan]\n",
    "                           })\n",
    "df_fig2_epi.to_csv('./figures/xgboost/fig2_epi_stats_2.csv')\n",
    "df_fig2_epi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame({'Age': y_epilepsy_sub_test[idx], 'Pred' : med_s[idx]})\n",
    "fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
    "sns.regplot(y=\"Pred\", x=\"Age\", data=df_);\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Pred');\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.savefig('./figures/xgboost/figure_2_insert_epilepsy.pdf')\n",
    "savemat('figure_2_xgboost_insert_epi.mat', {'real_epi': y_epilepsy_sub_test[idx], 'pred_epi': med_s[idx]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerated aging epilepsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_epi_ages = [a.predict(X_e_df) for a in all_models]\n",
    "all_pred_rns_ages = [a.predict(X_r_df) for a in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_epi_df = pd.concat([X_r_df, X_e_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ag_epi = np.where(y_epilepsy_sub_test < med_s)[0]\n",
    "acc_ag_epi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(all_models[0])\n",
    "epi_shap = explainer(X_epi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shap_epi = epi_shap[acc_ag_epi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 8))\n",
    "gs0 = gridspec.GridSpec(1, 4, figure=fig, width_ratios=[1, 0.05, 1, 0.05])\n",
    "\n",
    "labels = ['0.03', '0.1', '1', '4', '20']\n",
    "ticks = np.arange(50)[::10]\n",
    "\n",
    "shap_values = all_shap_epi\n",
    "pos_val = np.zeros((len(shap_values), 50, 50)) * np.nan\n",
    "neg_val = np.zeros((len(shap_values), 50, 50)) * np.nan\n",
    "pos_extra = np.zeros((len(shap_values), 4)) * np.nan\n",
    "neg_extra = np.zeros((len(shap_values), 4)) * np.nan\n",
    "for IDX in range(len(shap_values)):\n",
    "    _pos = copy.deepcopy(np.reshape(shap_values[IDX].values[:2500], (50, 50)))\n",
    "    _neg = copy.deepcopy(np.reshape(shap_values[IDX].values[:2500], (50, 50)))\n",
    "    _pos_e = copy.deepcopy(shap_values[IDX].values[2500:])\n",
    "    _neg_e = copy.deepcopy(shap_values[IDX].values[2500:])\n",
    "    \n",
    "    _pos[_pos < 0] = 0\n",
    "    pos_val[IDX] = _pos\n",
    "    _pos_e[_pos_e < 0] = 0\n",
    "    pos_extra[IDX] = _pos_e\n",
    "    \n",
    "    _neg[_neg > 0] = 0\n",
    "    neg_val[IDX] = _neg\n",
    "    _neg_e[_neg_e > 0] = 0\n",
    "    neg_extra[IDX] = _neg_e\n",
    "\n",
    "    \n",
    "m_pos = np.nanmean(pos_val, 0)\n",
    "mask = np.ones_like(m_pos)\n",
    "mask[m_pos < 0.01] = np.nan\n",
    "ax0 = fig.add_subplot(gs0[0, 0])\n",
    "im = ax0.imshow(m_pos * mask, cmap='Reds', vmax=1.2, vmin=0, aspect='auto')\n",
    "ax0.invert_yaxis()\n",
    "divider = make_axes_locatable(ax0)\n",
    "cax = divider.new_vertical(size=\"5%\", pad=.1, pack_start=False)\n",
    "fig.add_axes(cax)\n",
    "cb = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "cb.ax.xaxis.set_ticks_position('top')\n",
    "ax0.set_xticks(ticks)\n",
    "ax0.set_xticklabels(labels)\n",
    "ax0.xaxis.set_tick_params(rotation=45)\n",
    "ax0.set_yticks(ticks)\n",
    "ax0.set_yticklabels(labels)\n",
    "ax0.set_ylabel(r'$ITI(k + 1)$ [s]')\n",
    "ax0.set_xlabel(r'$ITI(k)$ [s]')\n",
    "ax0.text(-11, 50.1, 'Mean\\nShapley\\nvalue', size=25)\n",
    "    \n",
    "    \n",
    "ax01 = fig.add_subplot(gs0[0, 1])\n",
    "ax01.imshow(np.nanmean(pos_extra, 0)[:, None], vmax=1.2, vmin=0, cmap='Reds', aspect='auto')\n",
    "ax01.yaxis.tick_right()\n",
    "ax01.set_xticks([])\n",
    "ax01.set_yticks([0, 1, 2, 3])\n",
    "ax01.set_yticklabels([new_names[2500], new_names[2501], new_names[2502], new_names[2503]], rotation=90, size=15, verticalalignment='center')\n",
    "\n",
    "# ax99 = fig.add_subplot(gs0[0, 2])\n",
    "# ax99.set_xticks([])\n",
    "# ax99.set_yticks([])\n",
    "# ax99.spines['right'].set_visible(False)\n",
    "# ax99.spines['top'].set_visible(False)\n",
    "# ax99.spines['left'].set_visible(False)\n",
    "# ax99.spines['bottom'].set_visible(False)\n",
    "\n",
    "m_neg = np.nanmean(neg_val, 0)\n",
    "mask = np.ones_like(m_neg)\n",
    "mask[m_neg > -0.01] = np.nan\n",
    "ax1 = fig.add_subplot(gs0[0, 2])\n",
    "im = ax1.imshow(m_neg * mask, cmap=\"Blues_r\", vmin=-.8, vmax=0, aspect='auto')\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.new_vertical(size=\"5%\", pad=.1, pack_start=False)\n",
    "fig.add_axes(cax)\n",
    "cb = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "cb.ax.xaxis.set_ticks_position('top')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xticks(ticks)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.xaxis.set_tick_params(rotation=45)\n",
    "ax1.set_yticks(ticks)\n",
    "ax1.set_yticklabels(labels)\n",
    "ax1.set_ylabel(r'$ITI(k + 1)$ [s]')\n",
    "ax1.set_xlabel(r'$ITI(k)$ [s]')\n",
    "ax1.text(-11, 50.1, 'Mean\\nShapley\\nvalue', size=25)\n",
    "\n",
    "ax11 = fig.add_subplot(gs0[0, 3])\n",
    "ax11.imshow(np.nanmean(neg_extra, 0)[:, None], vmin=-0.8, vmax=0, cmap='Blues_r', aspect='auto')\n",
    "ax11.yaxis.tick_right()\n",
    "ax11.set_xticks([])\n",
    "ax11.set_yticks([0, 1, 2, 3])\n",
    "ax11.set_yticklabels([new_names[2500], new_names[2501], new_names[2502], new_names[2503]], rotation=90, size=15, verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/xgboost/accelerated_aging_epi.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.min(np.array([a.values for a in all_shap_epi]))\n",
    "vmax = np.max(np.array([a.values for a in all_shap_epi]))\n",
    "\n",
    "shap_values = all_shap_epi\n",
    "fig = plt.figure(figsize=(15, 34))\n",
    "main_grid = gridspec.GridSpec(11, 4,  figure=fig, height_ratios=[0.1] + [1] * 10)\n",
    "cax = fig.add_subplot(main_grid[0, :])\n",
    "\n",
    "for i, idx in enumerate(acc_ag_epi):\n",
    "    ax = fig.add_subplot(main_grid[i // 4 + 1, i % 4])\n",
    "    aa = np.reshape(shap_values[i].values[:2500], (50, 50))\n",
    "#     aa[np.abs(aa)<1e-3] = 0\n",
    "    im = ax.imshow(aa, norm=colors.TwoSlopeNorm(vcenter=0, vmin=vmin, vmax=vmax), aspect='auto', cmap='RdBu_r')\n",
    "    labels = ['0.03', '0.1', '1', '4', '20']\n",
    "    ticks = np.arange(50)[::10]\n",
    "\n",
    "#     divider = make_axes_locatable(ax)\n",
    "#     cax = divider.new_vertical(size=\"5%\", pad=.1, pack_start=False)\n",
    "#     fig.add_axes(cax)\n",
    "#     cb = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "#     cb.ax.xaxis.set_ticks_position('top')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    if (i % 4) == 0:\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_yticklabels(labels)\n",
    "        ax.set_ylabel(r'$ITI(k + 1)$ [s]')\n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "    if (i // 4) == 9:\n",
    "        ax.set_xticks(ticks)\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.xaxis.set_tick_params(rotation=45)\n",
    "        ax.set_xlabel(r'$ITI(k)$ [s]')\n",
    "    else:\n",
    "        ax.set_xticks([])\n",
    "    \n",
    "    ax.text(16,42,f\"chronological age: { y_epilepsy_sub_test[idx]}\\n      predicted age: {int(med_s[idx])}\", size=12, alpha=0.85)\n",
    "    \n",
    "cb = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "cb.ax.xaxis.set_ticks_position('top')\n",
    "cax.text(-2, 0, 'Shapley\\nvalue', size=25)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/xgboost/accelerated_aging_full_epi.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerated aging stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_str_ages = [a.predict(X_s_df) for a in all_models]\n",
    "acc_ag_str = np.where(y_stroke_sub_test < med_s_stroke)[0]\n",
    "acc_ag_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_str = shap.Explainer(all_models[0])\n",
    "str_shap = explainer_str(X_s_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shap_str = str_shap[acc_ag_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 8))\n",
    "gs0 = gridspec.GridSpec(1, 4, figure=fig, width_ratios=[1, 0.05, 1, 0.05])\n",
    "\n",
    "labels = ['0.03', '0.1', '1', '4', '20']\n",
    "ticks = np.arange(50)[::10]\n",
    "\n",
    "shap_values = all_shap_str\n",
    "pos_val = np.zeros((len(shap_values), 50, 50)) * np.nan\n",
    "neg_val = np.zeros((len(shap_values), 50, 50)) * np.nan\n",
    "pos_extra = np.zeros((len(shap_values), 4)) * np.nan\n",
    "neg_extra = np.zeros((len(shap_values), 4)) * np.nan\n",
    "for IDX in range(len(shap_values)):\n",
    "    _pos = copy.deepcopy(np.reshape(shap_values[IDX].values[:2500], (50, 50)))\n",
    "    _neg = copy.deepcopy(np.reshape(shap_values[IDX].values[:2500], (50, 50)))\n",
    "    _pos_e = copy.deepcopy(shap_values[IDX].values[2500:])\n",
    "    _neg_e = copy.deepcopy(shap_values[IDX].values[2500:])\n",
    "    \n",
    "    _pos[_pos < 0] = 0\n",
    "    pos_val[IDX] = _pos\n",
    "    _pos_e[_pos_e < 0] = 0\n",
    "    pos_extra[IDX] = _pos_e\n",
    "    \n",
    "    _neg[_neg > 0] = 0\n",
    "    neg_val[IDX] = _neg\n",
    "    _neg_e[_neg_e > 0] = 0\n",
    "    neg_extra[IDX] = _neg_e\n",
    "\n",
    "    \n",
    "m_pos = np.nanmean(pos_val, 0)\n",
    "mask = np.ones_like(m_pos)\n",
    "mask[m_pos < 0.01] = np.nan\n",
    "ax0 = fig.add_subplot(gs0[0, 0])\n",
    "im = ax0.imshow(m_pos * mask, cmap='Reds', vmax=1.2, vmin=0, aspect='auto')\n",
    "ax0.invert_yaxis()\n",
    "divider = make_axes_locatable(ax0)\n",
    "cax = divider.new_vertical(size=\"5%\", pad=.1, pack_start=False)\n",
    "fig.add_axes(cax)\n",
    "cb = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "cb.ax.xaxis.set_ticks_position('top')\n",
    "ax0.set_xticks(ticks)\n",
    "ax0.set_xticklabels(labels)\n",
    "ax0.xaxis.set_tick_params(rotation=45)\n",
    "ax0.set_yticks(ticks)\n",
    "ax0.set_yticklabels(labels)\n",
    "ax0.set_ylabel(r'$ITI(k + 1)$ [s]')\n",
    "ax0.set_xlabel(r'$ITI(k)$ [s]')\n",
    "ax0.text(-11, 50.1, 'Mean\\nShapley\\nvalue', size=25)\n",
    "    \n",
    "    \n",
    "ax01 = fig.add_subplot(gs0[0, 1])\n",
    "ax01.imshow(np.nanmean(pos_extra, 0)[:, None], vmax=1.2, vmin=0, cmap='Reds', aspect='auto')\n",
    "ax01.yaxis.tick_right()\n",
    "ax01.set_xticks([])\n",
    "ax01.set_yticks([0, 1, 2, 3])\n",
    "ax01.set_yticklabels([new_names[2500], new_names[2501], new_names[2502], new_names[2503]], rotation=90,size=15, verticalalignment='center')\n",
    "\n",
    "# ax99 = fig.add_subplot(gs0[0, 2])\n",
    "# ax99.set_xticks([])\n",
    "# ax99.set_yticks([])\n",
    "# ax99.spines['right'].set_visible(False)\n",
    "# ax99.spines['top'].set_visible(False)\n",
    "# ax99.spines['left'].set_visible(False)\n",
    "# ax99.spines['bottom'].set_visible(False)\n",
    "\n",
    "m_neg = np.nanmean(neg_val, 0)\n",
    "mask = np.ones_like(m_neg)\n",
    "mask[m_neg > -0.01] = np.nan\n",
    "ax1 = fig.add_subplot(gs0[0, 2])\n",
    "im = ax1.imshow(m_neg * mask, cmap=\"Blues_r\", vmin=-0.8, vmax=0, aspect='auto')\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.new_vertical(size=\"5%\", pad=.1, pack_start=False)\n",
    "fig.add_axes(cax)\n",
    "cb = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "cb.ax.xaxis.set_ticks_position('top')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xticks(ticks)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.xaxis.set_tick_params(rotation=45)\n",
    "ax1.set_yticks(ticks)\n",
    "ax1.set_yticklabels(labels)\n",
    "ax1.set_ylabel(r'$ITI(k + 1)$ [s]')\n",
    "ax1.set_xlabel(r'$ITI(k)$ [s]')\n",
    "ax1.text(-11, 50.1, 'Mean\\nShapley\\nvalue', size=25)\n",
    "\n",
    "ax11 = fig.add_subplot(gs0[0, 3])\n",
    "ax11.imshow(np.nanmean(neg_extra, 0)[:, None], vmin=-0.8, vmax=0, cmap='Blues_r', aspect='auto')\n",
    "ax11.yaxis.tick_right()\n",
    "ax11.set_xticks([])\n",
    "ax11.set_yticks([0, 1, 2, 3])\n",
    "ax11.set_yticklabels([new_names[2500], new_names[2501], new_names[2502], new_names[2503]], rotation=90, size=15, verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/xgboost/accelerated_aging_stroke.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ag_str.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.min(np.array([a.values for a in all_shap_str]))\n",
    "vmax = np.max(np.array([a.values for a in all_shap_str]))\n",
    "\n",
    "shap_values = all_shap_str\n",
    "fig = plt.figure(figsize=(15, 25))\n",
    "\n",
    "main_grid = gridspec.GridSpec(8, 4,  figure=fig, height_ratios=[0.1] + [1] * 7)\n",
    "cax = fig.add_subplot(main_grid[0, :])\n",
    "\n",
    "for i, idx in enumerate(acc_ag_str[:28]):\n",
    "    ax = fig.add_subplot(main_grid[i // 4 + 1, i % 4])\n",
    "    aa = np.reshape(shap_values[i].values[:2500], (50, 50))\n",
    "#     aa[np.abs(aa)<1e-3] = 0\n",
    "    im = ax.imshow(aa, norm=colors.TwoSlopeNorm(vcenter=0, vmin=vmin, vmax=vmax), aspect='auto', cmap='RdBu_r')\n",
    "    labels = ['0.03', '0.1', '1', '4', '20']\n",
    "    ticks = np.arange(50)[::10]\n",
    "\n",
    "#     divider = make_axes_locatable(ax)\n",
    "#     cax = divider.new_vertical(size=\"5%\", pad=.1, pack_start=False)\n",
    "#     fig.add_axes(cax)\n",
    "#     cb = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "#     cb.ax.xaxis.set_ticks_position('top')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    if (i % 4) == 0:\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_yticklabels(labels)\n",
    "        ax.set_ylabel(r'$ITI(k + 1)$ [s]')\n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    if (i // 4) == 6:\n",
    "        ax.set_xticks(ticks)\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.xaxis.set_tick_params(rotation=45)\n",
    "        ax.set_xlabel(r'$ITI(k)$ [s]')\n",
    "    else:\n",
    "        ax.set_xticks([])\n",
    "    \n",
    "    ax.text(16,42,f\"chronological age: { y_stroke_sub_test[idx]}\\n      predicted age: {int(med_s_stroke[idx])}\", size=12, alpha=0.85)\n",
    "\n",
    "cb = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "cb.ax.xaxis.set_ticks_position('top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/xgboost/accelerated_aging_full_stroke.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_info = pd.read_csv('more_info_for_review_ml_age.csv')\n",
    "more_info = more_info.drop(503)\n",
    "more_info.insert(1, \"entropy\", e_708)\n",
    "more_info = more_info[more_info.age > 0]\n",
    "more_info = more_info[more_info.n_taps > 100]\n",
    "more_info = more_info[more_info.n_days > 7]\n",
    "more_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to put NaN where info is missing\n",
    "more_info.phoneModel.replace(0, np.nan, inplace=True)\n",
    "more_info.n_apps.replace([0, 1], np.nan, inplace=True)\n",
    "more_info['fingerdness(1)'].replace(-1, np.nan, inplace=True)\n",
    "more_info['fingerdness(2)'].replace(-1, np.nan, inplace=True)\n",
    "more_info.yearsused.replace(-1, np.nan, inplace=True)\n",
    "more_info.mcs.replace(-1, np.nan, inplace=True)\n",
    "more_info.pcs.replace(-1, np.nan, inplace=True)\n",
    "more_info.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_m = more_info[more_info.gender == 1]\n",
    "info_f = more_info[more_info.gender == 2]\n",
    "\n",
    "info_m = info_m.sort_values('age')\n",
    "info_f = info_f.sort_values('age')\n",
    "len(info_m), len(info_f)\n",
    "info_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(info_m), len(info_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 20))\n",
    "gs0 = gridspec.GridSpec(2, 6, figure=fig, height_ratios=[len(info_m) / len(info_f), 1], wspace=0.5)\n",
    "\n",
    "# male\n",
    "cmap = \"Blues\"\n",
    "ax = [fig.add_subplot(gs0[0, i]) for i in range(6)]\n",
    "im0 = ax[0].imshow(np.log10(info_m['usage']).values[:, None], aspect='auto', interpolation=None, cmap=cmap)\n",
    "im1 = ax[1].imshow(info_m['phoneModel'].values[:, None], aspect='auto', interpolation=None, cmap=cmap)\n",
    "im2 = ax[2].imshow(info_m['entropy'].values[:, None], aspect='auto', interpolation=None, cmap=cmap)\n",
    "im4 = ax[4].imshow(info_m['mcs'].values[:, None], aspect='auto', interpolation=None, cmap=cmap)\n",
    "im5 = ax[5].imshow(info_m['pcs'].values[:, None], aspect='auto', interpolation=None, cmap=cmap)\n",
    "for _ax, _im, _cb_r, _title in zip([ax[0], ax[1], ax[2], ax[4], ax[5]], \n",
    "                    [im0, im1, im2, im4, im5], \n",
    "                    [[2, 4], [5, 10], [6, 9], [0, 85], [0, 85]], \n",
    "                    [\"Usage \\n(Log10 no. of\\n interactions/day)\", \"Screen size \\n(inches)\", \"Entropy (bits)\", \"MCS (SF36)\", \"PCS (SF36)\"]):\n",
    "    _ax.grid(0)\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "    divider = make_axes_locatable(_ax)\n",
    "    cax = divider.new_vertical(size=\"5%\", pad=.1, pack_start=False)\n",
    "    fig.add_axes(cax)\n",
    "    cb = fig.colorbar(_im, cax=cax, orientation=\"horizontal\")\n",
    "    cb.ax.xaxis.set_ticks_position('top')\n",
    "#     cb.ax.xaxis.set_ticks(_cb_r)\n",
    "    _ax.set_title(_title, pad=70, size=12)\n",
    "\n",
    "ax[0].set_yticks(range(0, len(info_m), 30))\n",
    "ax[0].set_yticklabels([info_m.age.values[i] for i in range(0, len(info_m), 30)])\n",
    "ax[0].set_ylabel(\"Age \\u2642 [years]\")\n",
    "\n",
    "    \n",
    "for _ax in [ax[3]]:\n",
    "    _ax.grid(0)\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "    _ax.spines['right'].set_visible(False)\n",
    "    _ax.spines['left'].set_visible(False)\n",
    "    _ax.spines['top'].set_visible(False)\n",
    "    _ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# female\n",
    "ax = [fig.add_subplot(gs0[1, i]) for i in range(6)]\n",
    "cmap = \"Reds\"\n",
    "im0 = ax[0].imshow(np.log10(info_f['usage']).values[:, None], aspect='auto', interpolation=None, cmap=cmap)\n",
    "im1 = ax[1].imshow(info_f['phoneModel'].values[:, None], aspect='auto', interpolation=None, cmap=cmap)\n",
    "im2 = ax[2].imshow(info_f['entropy'].values[:, None], aspect='auto', interpolation=None, cmap=cmap)\n",
    "im4 = ax[4].imshow(info_f['mcs'].values[:, None], aspect='auto', interpolation=None, cmap=cmap)\n",
    "im5 = ax[5].imshow(info_f['pcs'].values[:, None], aspect='auto', interpolation=None, cmap=cmap)\n",
    "for _ax, _im, _cb_r in zip([ax[0], ax[1], ax[2], ax[4], ax[5]], \n",
    "                    [im0, im1, im2, im4, im5],\n",
    "                    [[2, 4], [5, 10], [6, 9], [0, 85], [0, 85]]):\n",
    "    _ax.grid(0)\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "    divider = make_axes_locatable(_ax)\n",
    "    cax = divider.new_vertical(size=\"5%\", pad=.1, pack_start=False)\n",
    "    fig.add_axes(cax)\n",
    "    cb = fig.colorbar(_im, cax=cax, orientation=\"horizontal\")\n",
    "    cb.ax.xaxis.set_ticks_position('top')\n",
    "#     cb.ax.xaxis.set_ticks(_cb_r)\n",
    "    \n",
    "for _ax in [ax[3]]:\n",
    "    _ax.grid(0)\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "    _ax.spines['right'].set_visible(False)\n",
    "    _ax.spines['left'].set_visible(False)\n",
    "    _ax.spines['top'].set_visible(False)\n",
    "    _ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "ax[0].set_yticks(range(0, len(info_f), 30))\n",
    "ax[0].set_yticklabels([info_f.age.values[i] for i in range(0, len(info_f), 30)])\n",
    "ax[0].set_ylabel(\"Age \\u2640 [years]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/xgboost/figure_1_more_info_columns.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xg-gpu",
   "language": "python",
   "name": "xg-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "262px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
